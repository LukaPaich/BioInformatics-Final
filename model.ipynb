{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8984713,"sourceType":"datasetVersion","datasetId":5410857},{"sourceId":8999439,"sourceType":"datasetVersion","datasetId":5421059}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def install_and_import(package):\n    import importlib\n    try:\n        importlib.import_module(package)\n    except ImportError:\n        import pip\n        pip.main(['install', package])\n    finally:\n        globals()[package] = importlib.import_module(package)\n\n\ninstall_and_import('einops')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:07:50.107496Z","iopub.execute_input":"2024-07-20T21:07:50.108004Z","iopub.status.idle":"2024-07-20T21:07:50.114387Z","shell.execute_reply.started":"2024-07-20T21:07:50.107969Z","shell.execute_reply":"2024-07-20T21:07:50.113225Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ninput_file = '/kaggle/input/pipeline-dataset/chr14_training_dataset.csv'\n# Load the dataset\ndf = pd.read_csv(input_file)\n\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:07:50.116332Z","iopub.execute_input":"2024-07-20T21:07:50.116643Z","iopub.status.idle":"2024-07-20T21:07:50.255046Z","shell.execute_reply.started":"2024-07-20T21:07:50.116617Z","shell.execute_reply":"2024-07-20T21:07:50.254071Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"                                                sequence  label\n0      TAAAGAGACAAGCACTATATGCCTGTAGTACCTGCACCCCAGAGGG...      0\n1      TGGTGGTCCGGGGCCGCCGTTAGTCTGCCGCTTCCTCACCCCAAGC...      0\n2      GCTTGCAGTTATGAATGTCATGGAAGTCACAAACTATTTGAGCTAT...      1\n3      ATCTTGGTGCCATTCCCCCTGAGAGTGGGGATTTTCAGGAGATGGT...      0\n4      ACCTTTTGAAACCATTGTTGTCACAAAAAGATAAAGGTTATATTTT...      0\n...                                                  ...    ...\n72673  atacaggagcacccagattcataaagcaagtccttagagacctaca...      0\n72674  AGAGTCAAGTCCCTGGGAACTTCAGGAAGCAGCccaccatgtttca...      1\n72675  GAAAAGATGCATGAAGACACAGAAAAGAAACTAAAGGAAACAGCTG...      0\n72676  ttatgggctggaacacttttatcttggcagtcccataatctagGAT...      0\n72677  CTGGATCCAATGTTAGTCTTTTCACTTTCAGGAGATAGAAAAGATG...      1\n\n[72678 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport datasets\nfrom datasets import Dataset, DatasetDict\n\ndataset = Dataset.from_csv(input_file)\nprint(dataset)\n\ntrain_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:07:50.256134Z","iopub.execute_input":"2024-07-20T21:07:50.256433Z","iopub.status.idle":"2024-07-20T21:07:51.220380Z","shell.execute_reply.started":"2024-07-20T21:07:50.256407Z","shell.execute_reply":"2024-07-20T21:07:51.219592Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"620128ff1f8e4b1aa2019e99f9ae49e3"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['sequence', 'label'],\n    num_rows: 72678\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ntrain_data = pd.DataFrame.from_dict(train_data)\nval_data = pd.DataFrame.from_dict(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:07:51.222231Z","iopub.execute_input":"2024-07-20T21:07:51.222540Z","iopub.status.idle":"2024-07-20T21:07:51.264692Z","shell.execute_reply.started":"2024-07-20T21:07:51.222514Z","shell.execute_reply":"2024-07-20T21:07:51.263796Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(train_data)\nprint(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:07:51.265848Z","iopub.execute_input":"2024-07-20T21:07:51.266196Z","iopub.status.idle":"2024-07-20T21:07:51.280217Z","shell.execute_reply.started":"2024-07-20T21:07:51.266149Z","shell.execute_reply":"2024-07-20T21:07:51.279221Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"                                                sequence  label\n0      CCAAATGGGATGTGTTTTTCTTATATACAAGTTGTTCACTTTGAAA...      0\n1      AAAGACAGCCCCTCCATGTGAGGAAGCCCCCAACTGGGGAAAACCC...      0\n2      CGTGTGCCATGTGGGGAAGGCGGAGGACCGGGAGCGGCTGGTGGCC...      1\n3      gggcatgactgTAGTTGTTTCCCTCTGTAGTCGTAGTCGAGATCGG...      1\n4      TAATGCCAGCTCAAAAACAGAGCTGACCATTTCTCTTTCATATGTT...      1\n...                                                  ...    ...\n58137  TTAAGGGTGATCTGCCAGATTGCGAAGCTGACCAACTCCTGCAGAT...      0\n58138  AGGGAGGCAAATGCCTAACCTATGCTAAAGACGCATTATGCTAGGA...      0\n58139  AGAACCTCCACTGACCTTCAGGAAGCAGGAGTGCTAGAAAGTACAG...      0\n58140  GTTTCCTGTATTCCTGAGATCATTGTTTATTTTTCTTATTCTCTCT...      1\n58141  TCCTTGACAAAACGAAAAACAATTGGGAAGATCGAGAAAAGTTTGA...      0\n\n[58142 rows x 2 columns]\n                                                sequence  label\n0      TGCTCTGGCCCCTGGACTCACCGTGTGTTCTCCCTTCTTCCACCCC...      1\n1      TTATAAAAATACTTAACATTCATTGTTTTTTTAAAAAAGACATTAT...      0\n2      TGTCAGTATGTTGTGACATGTGCAGGACTTTACTCAGACCGTATTT...      0\n3      CCGTAAGCAAGGGTCTTCAAGGCCCGGGTTGCTGGTGGAGAGAGAC...      0\n4      CTGCCCCAAAGGCACCTATCAAAGACCCTGCAAACAAGCAGATGGC...      0\n...                                                  ...    ...\n14531  TGCCACCCAGCTGCCTTTGGAGAATGCTCTGGCCCCTGGACTCACC...      1\n14532  GGCCTCACACCACTGTTACTTGGTGTACATGAGCAAAAACAGCAAG...      0\n14533  TGGACGGACAATCAGCCGTGCTGGTCTGGAACTGGGAGCAGAGCCT...      1\n14534  GGGAAATATCTTGCTGTAGCATCCCATGACAGCTTTATAGATATAT...      0\n14535  aaacccagacagtgaagactacaataaatacctaactcttcaatgc...      0\n\n[14536 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers.models.bert.configuration_bert import BertConfig\nfrom transformers import AutoModel, AutoTokenizer\nimport torch\n\ntokenizer = tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n\ndef tokenize_data(df, tokenizer):\n    return tokenizer(df['sequence'].tolist(), padding=True, truncation=True, return_tensors='pt')\n\ntrain_encodings = tokenize_data(train_data, tokenizer)\nval_encodings = tokenize_data(val_data, tokenizer)\n\ntrain_labels = torch.tensor(train_data['label'].values)\nval_labels = torch.tensor(val_data['label'].values)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:07:51.281375Z","iopub.execute_input":"2024-07-20T21:07:51.281884Z","iopub.status.idle":"2024-07-20T21:08:03.802466Z","shell.execute_reply.started":"2024-07-20T21:07:51.281856Z","shell.execute_reply":"2024-07-20T21:08:03.801473Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(train_labels))\nprint(len(val_labels))","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:03.803924Z","iopub.execute_input":"2024-07-20T21:08:03.804679Z","iopub.status.idle":"2024-07-20T21:08:03.810097Z","shell.execute_reply.started":"2024-07-20T21:08:03.804644Z","shell.execute_reply":"2024-07-20T21:08:03.809112Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"58142\n14536\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass DnaDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = DnaDataset(train_encodings, train_labels)\nval_dataset = DnaDataset(val_encodings, val_labels)\n\nprint(train_dataset)\nprint(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:03.811577Z","iopub.execute_input":"2024-07-20T21:08:03.811906Z","iopub.status.idle":"2024-07-20T21:08:03.821044Z","shell.execute_reply.started":"2024-07-20T21:08:03.811876Z","shell.execute_reply":"2024-07-20T21:08:03.820115Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"<__main__.DnaDataset object at 0x7eb58026b760>\n<__main__.DnaDataset object at 0x7eb58026a530>\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\nimport wandb\nwandb.login(key=\"WANDB_API_KEY\")\nwandb.init(project=\"dna-classification\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:03.823751Z","iopub.execute_input":"2024-07-20T21:08:03.824073Z","iopub.status.idle":"2024-07-20T21:08:20.874329Z","shell.execute_reply.started":"2024-07-20T21:08:03.824050Z","shell.execute_reply":"2024-07-20T21:08:20.873470Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240720_210803-detw2ndu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification/runs/detw2ndu' target=\"_blank\">usual-haze-8</a></strong> to <a href='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification' target=\"_blank\">https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification/runs/detw2ndu' target=\"_blank\">https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification/runs/detw2ndu</a>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification/runs/detw2ndu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7eb5a882fc40>"},"metadata":{}}]},{"cell_type":"code","source":"config = BertConfig.from_pretrained(\"zhihan1996/DNABERT-2-117M\", num_labels=2)\nmodel = AutoModelForSequenceClassification.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True, config=config)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=50,\n    report_to=\"wandb\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:20.875688Z","iopub.execute_input":"2024-07-20T21:08:20.876239Z","iopub.status.idle":"2024-07-20T21:08:21.801485Z","shell.execute_reply.started":"2024-07-20T21:08:20.876204Z","shell.execute_reply":"2024-07-20T21:08:21.800391Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/root/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/d064dece8a8b41d9fb8729fbe3435278786931f1/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n  warnings.warn(\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n\n# Define compute_metrics function\ndef compute_metrics(pred):\n    logits = pred.predictions[0] if isinstance(pred.predictions, tuple) else pred.predictions\n    preds = logits.argmax(-1)\n    labels = pred.label_ids\n    accuracy = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='weighted')\n    precision, recall, _, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:21.802856Z","iopub.execute_input":"2024-07-20T21:08:21.803148Z","iopub.status.idle":"2024-07-20T21:08:21.810133Z","shell.execute_reply.started":"2024-07-20T21:08:21.803123Z","shell.execute_reply":"2024-07-20T21:08:21.809219Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:21.811585Z","iopub.execute_input":"2024-07-20T21:08:21.811883Z","iopub.status.idle":"2024-07-20T21:08:21.974379Z","shell.execute_reply.started":"2024-07-20T21:08:21.811861Z","shell.execute_reply":"2024-07-20T21:08:21.973144Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:08:21.975668Z","iopub.execute_input":"2024-07-20T21:08:21.975948Z","iopub.status.idle":"2024-07-20T21:36:48.327460Z","shell.execute_reply.started":"2024-07-20T21:08:21.975924Z","shell.execute_reply":"2024-07-20T21:36:48.326683Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5451' max='5451' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5451/5451 28:25, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.670300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.618400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.618600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.607700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.597800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.595400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.627200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.569100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.509300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.443900</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.452700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.532100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.442800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.454300</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.467100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.416700</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.403700</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.410900</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.396500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.404400</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.380800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.391600</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.366700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.413700</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.415900</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.432500</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.408300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.354000</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.340600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.337300</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.339100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.380200</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.333300</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.343000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.327500</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.333300</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.291800</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.331900</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.335900</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.295000</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.267300</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.279300</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.274700</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.287700</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.276700</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.303000</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.306200</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.292200</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.279700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.350100</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.265600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.278200</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.264400</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.285800</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.240000</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.290800</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.244600</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.269800</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.265500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.235900</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>0.278200</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.284200</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>0.263700</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.256500</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.237500</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.261100</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>0.260800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.238200</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>0.278900</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.260100</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>0.217300</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.272200</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>0.195700</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.229300</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>0.187200</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.194700</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>0.211900</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.222500</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>0.232800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.225800</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>0.210400</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.179200</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>0.220200</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.211800</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>0.225500</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.223900</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>0.208000</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.202200</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>0.210800</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.199000</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>0.184500</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.192000</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>0.219200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.227400</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>0.191000</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.191800</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>0.211100</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.181900</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>0.177200</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.184100</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>0.257000</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.215500</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>0.191400</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.197900</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>0.234800</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.206300</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>0.205500</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.191200</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>0.193800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5451, training_loss=0.30919973940132867, metrics={'train_runtime': 1705.7094, 'train_samples_per_second': 102.26, 'train_steps_per_second': 3.196, 'total_flos': 1.2161114088910416e+16, 'train_loss': 0.30919973940132867, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate on test set\nresults = trainer.evaluate(eval_dataset=val_dataset)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:36:48.328477Z","iopub.execute_input":"2024-07-20T21:36:48.328745Z","iopub.status.idle":"2024-07-20T21:37:27.313920Z","shell.execute_reply.started":"2024-07-20T21:36:48.328722Z","shell.execute_reply":"2024-07-20T21:37:27.312647Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [114/114 00:34]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22098875045776367, 'eval_accuracy': 0.9287286736378646, 'eval_f1': 0.9285576496130549, 'eval_precision': 0.9284660023521114, 'eval_recall': 0.9287286736378646, 'eval_runtime': 38.705, 'eval_samples_per_second': 375.558, 'eval_steps_per_second': 2.945, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Finish the wandb run\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T21:37:27.315694Z","iopub.execute_input":"2024-07-20T21:37:27.316117Z","iopub.status.idle":"2024-07-20T21:37:31.283279Z","shell.execute_reply.started":"2024-07-20T21:37:27.316078Z","shell.execute_reply":"2024-07-20T21:37:31.282345Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▂▂▂▃█▃▂▂▁▄▂▂▁▁▄▃▁▃▄▁▂▅▁▁▃▁▁▁▁▂▁▁▁▂▅▂▁▃▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▇▆▆▅▄▄▄▄▃▃▃▃▃▂▂▃▃▂▃▂▂▂▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.92873</td></tr><tr><td>eval/f1</td><td>0.92856</td></tr><tr><td>eval/loss</td><td>0.22099</td></tr><tr><td>eval/precision</td><td>0.92847</td></tr><tr><td>eval/recall</td><td>0.92873</td></tr><tr><td>eval/runtime</td><td>38.705</td></tr><tr><td>eval/samples_per_second</td><td>375.558</td></tr><tr><td>eval/steps_per_second</td><td>2.945</td></tr><tr><td>total_flos</td><td>1.2161114088910416e+16</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>5451</td></tr><tr><td>train/grad_norm</td><td>0.94856</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1938</td></tr><tr><td>train_loss</td><td>0.3092</td></tr><tr><td>train_runtime</td><td>1705.7094</td></tr><tr><td>train_samples_per_second</td><td>102.26</td></tr><tr><td>train_steps_per_second</td><td>3.196</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">usual-haze-8</strong> at: <a href='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification/runs/detw2ndu' target=\"_blank\">https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification/runs/detw2ndu</a><br/> View project at: <a href='https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification' target=\"_blank\">https://wandb.ai/gkldi20-free-university-of-tbilisi/dna-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240720_210803-detw2ndu/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}